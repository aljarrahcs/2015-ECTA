\documentclass{llncs}

\usepackage{subfigure}
\usepackage{calc}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{pslatex}
\usepackage{hyperref}

\subfigtopskip=0pt
\subfigcapskip=0pt
\subfigbottomskip=0pt

\begin{document}
%\SweaveOpts{concordance=TRUE}
<<setup, cache=FALSE,echo=FALSE>>=
#You've got to install all these libraries if you want to compile the paper.
library("ggplot2")
library("RCurl") #To download stuff directly from the GitHub repo
library(e1071) # for skewness and kurtosis
# Now download stuff from noisy-ga repo
made.data <- read.csv(text = getURL("https://raw.githubusercontent.com/JJ/noisy-ga/master/data/MADE/made-data.csv"))
pacman.data <-  read.csv(text = getURL("https://raw.githubusercontent.com/JJ/noisy-ga/master/data/ms-pacman/pacman-fitness.csv"))
planetwars.data <- read.csv(text = getURL("https://raw.githubusercontent.com/JJ/noisy-ga/master/data/planet-wars/planetwars-fitness.csv"))
starcraft.data <- read.csv("../data/starcraftdata/starcraft-data.csv")
mlp.data <- read.csv("../data/MLP/data-mlp.csv")
@ 


\title{The Uncertainty Quandary: A Study in the Context of the
  Evolutionary Optimization of Games and other uncertain environments} 
% Antonio - 'of games' -> 'in games' or in another type of problems if we include MLP results
% Alberto - I am writing some general observations inside the master branch as if it there was no tomorrow. Also, as a general observation, the word 'crisp' is repeated about 10^80 times. You might want to find some synonyms. Also, when we speak about "fitness", IMHO is kindof weird. We should speak either of "fitness functions" or "fitness values", to be more understandable.

% Don't like it too much, but at least it's honest and true.
% Antonio - I fix it and propose a change "Noise plays: a study of uncertainty in the context of evolutionary optimization in games"

\author{Juan J. Merelo\inst{1} \and 
    Federico Liberatore\inst{1},
    Antonio Fern{\'a}ndez Ares\inst{1} \and 
    Rub{\'e}n Garc{\'i}a\inst{2} \and 
    Zeineb Chelly\inst{3} \and 
    Carlos Cotta\inst{4} \and 
    Nuria Rico\inst{5} \and 
    Antonio M. Mora\inst{1} \and
    Pablo Garc{\'i}a-S{\'a}nchez\inst{1} \and
    Alberto Tonda\inst{6} \and
    Paloma de las Cuevas\inst{1} \and 
    Pedro A. Castillo\inst{1}}

\institute{Depto. ATC, University of Granada, Spain\\
\email{\tt jmerelo@geneura.ugr.es} \and
Escuela de Doctorado, University of Granada, Spain \and
Lab. LARODEC, Institut Sup\'erieur de Gestion, Tunisia \and
Depto. LCC, University of M{\'a}laga, Spain \and
Depto. EIO, University of Granada, Spain \and
UMR 782 GMPA, INRA, Thiverval-Grignon, France
}

\maketitle 

%\keywords{Games, evolutionary optimization, noise, uncertainty, noisy fitness}

\begin{abstract}
% Antonio - I rewrite the abstract (It tells the same but in other words)  
% Alberto - I also rewrote the abstract :-)
  % Too many rewrites spoil the soup - JJ 
  In many optimization processes, the fitness or the
  considered measure of goodness for the candidate solutions
  presents \textit{uncertainty}, that is, yields different
  values when repeatedly measured, due to the nature of the evaluation 
  process or
  the solution itself. This happens quite often in the context of
  computational intelligence in games, when either bots behave
  stochastically, or the target game possesses intrinsic random elements. 
  Thus, it is important to examine the statistical behavior of such
  performance measurements and, more specifically, the statistical distribution
  that better fits them. This work analyzes four different problems
  related to computational intelligence in videogames, where Evolutionary Computation
  methods have been applied, and the evaluation of each
  individual is performed by playing the game, and compares it to
  other problem, neural network optimization, where the solution is
  also certain. 
In order to find a pattern in the statistical behavior of the
variables, we track the main features of the distributions, \textit{skewness}
and \textit{kurtosis}. Contrary to the usual assumption in this kind of problems,
we prove that, in general, these two features do not follow a normal
distribution, but they do present a certain common behavior that changes as evolution
proceeds, getting in some cases closer to the standard distribution
and in others drifting apart from it. A clear behavior in this case
cannot be concluded, other than the fact that the statistical
distribution that fitness variables follow is affected by selection in
different directions, that parameters vary in a single generation
across them, and that, in general, this kind of behavior will have to
be taken into account to adequately address uncertainty in fitness in
evolutionary algorithms. 
% Antonio - add a line with the conclusion. What does this mean?
% Alberto - also, are we sure that in some cases skewness and kurtosis are moving away from a normal distribution, and not just happily jumping around?
\end{abstract}


% ******************************************************************************

\section{Introduction}
\label{sec:introduction}

Optimization methods usually need a crisp and reliable feedback to work
correctly. This value, usually called {\em cost} or {\em fitness},
informs the algorithm on the goodness of the solution and, when facing different alternatives, it is used to
select a particular solution over others. This does not imply the necessity of a single floating point number as feedback; since these methodology are based on
comparisons, it is usually enough if the values can be partially
ordered. In multiobjective optimization \cite{Deb2001}, for instance, two solutions can even be considered {\em non-comparable}, based on the set of fitness values they possess.
%Multiobjective optimization, for instance, just needs to know
%when comparing two solutions whether one or the other is the best or there
%can be no comparison between them.
In either case, the answer to the
question ``Is this solution better than the other?'' needs to be either a
`Yes', or `No', or `It's impossible to know'.



In many cases, however, the fitness or cost of a solution cannot be
described by a crisp value, because there is  \textit{uncertainty} in the measure. 
Such uncertainty is inherent to most real-world physical systems, such as the one described in \cite{esann94}, where a
control system is optimized through a stochastic procedure. 
In these cases, the best way to describe a solution will be a random
variable, not a single value or a vector of deterministic values.
In our research, we routinely find this phenomenon in different
optimization problems, such as:
\begin{itemize}
  \item optimizing the layout of a web-page using Simulated
  Annealing (SA) \cite{jj-ppsn98}. Since SA is a stochastic procedure, the fitness  of an obtained solution will be a random variable.
  %PABLO: at a first glance I thought each solutions had stochastic fitness, but it is the value of the 'obtained' final solution, so I moved "obtained".
\item training any kind of neural network
  \cite{esann94,merelo:ESNN}; in the second case we dealt with a
  physical installation, introducing another kind of randomness. Since
  training a neural network is a stochastic procedure, the error rate
  obtained after every training run will also follow  a statistical
  distribution. 
\item evolving game bots (autonomous agents) \cite{bots:evostar}. In this case, the
  uncertainty arises from the problem itself; in games, several
  factors such as the initial positions of the players or the
  opponent's behavior add further stochastic components, so that the final
  score will also be {\em uncertain} or {\em noisy}. In some cases,
  too, the bot itself will rely on probabilities to 
  generate its behavior \cite{EvoStar2014:CoEvolutionary}, in which
  case two different runs with exactly the same initial conditions and
  opponent will also yield different scores.
\end{itemize}

In all these examples, it cannot be said that there is actually {\em noise} added to
a {\em crisp} fitness. Instead, the fitness itself can be represented with a statistical variable,
whose value arises from a stochastic process, evaluation, or
training. 

%The main issue we try to solve in this problem is the lack
%of an exhaustive research on the behavior of fitness as a random variable.
Despite a considerable amount of literature on problems with stochastic fitness values, there is a distinct lack of exhaustive research on the behavior of fitness functions, seen as random variables.
That is why, after an initial study of noise in a specific game in
\cite{merelo14:noisy}, 
%where our findings indicated that, in some cases, noise followed a
%Gamma distribution, that
%is, a skewed normal distribution and proposing a solution to this using
%Wilcoxon comparison \ref{wilcoxon:1945} as a selection operator, 
we dug into data discovering that, even if the distribution in that
particular case was always a Gamma, the parameters of the distribution
were different. In that study, we proposed a solution to the noise issue, based on using the Wilcoxon comparison \cite{wilcoxon:1945} as a selection operator.
This meant that the random variable behaved in different ways
depending on the particular individual, the state of evolution and, of
course, the specific problem.

But, more importantly, this initial conclusion disagrees with the usual assumptions of
optimization in uncertain environments, where it is frequent to take a normal distribution of noise with fixed $\sigma$ as the initial hypothesis \cite{arnold2001evolution}. For instance, in the functions of the Black Box
Optimization Benchmarks \cite{hansen2009real}, uncertainty was
simulated by adding a Cauchy noise function centered in 0,
that is, a centered, sharp bell-shaped distribution,
with different widths. Either multiplicative or additive noise has
been used in different occasions. However, our initial work hints
that this is not the case in real-world optimization problems, 
ultimately invalidating the generality of the conclusions 
on different optimization methods
obtained through the usual benchmarks.
%rendering
%the conclusions achieved on the goodness of one or other method not
%applicable. 
Besides, we also prove in \cite{merelo14:noisy} that,
depending on the shape of the statistical distribution of the fitness,
different methods could yield the best results. While methods that
use the median or average would work well in centered distributions,
other methods such as our technique, based on the Wilcoxon test, are better
in more uncertain environments or, of course, in the case the
noise distribution is not centered. 

In this paper, we collect data from several different
case studies, which will be presented later on, to find a stochastic model
for the fitness using statistical 
tools. Our final objective is to eventually build a model as general
as possible, able to account for most sources of
uncertainty; failing that, to devise selection operators that %PABLO: paloma told me in the mail that this "failing that" is weird. Other option?
% not really. Tell Paloma to change it here - JJ
are able to work with random fitness in a natural way. 
%However, this
%is not the focus of this paper and, if it is eventually needed, is
%left as future work.
This second part, if needed, will be the focus of future research.

The rest of the paper is organized as follows. In Section \ref{sec:soa} we present the
state of the art for evolutionary algorithms in uncertain environments,
to be followed by a short presentation of the four problems with
uncertainty whose measures will be used in this paper in Section
\ref{sec:problems}. Results will be presented in Section
\ref{sec:res}, followed by our conclusions.

% ******************************************************************************

\section{State of the Art}
\label{sec:soa}

\sloppypar The most comprehensive, although not recent, review of the state of the art for 
evolutionary algorithms in {\em uncertain} environments 
is presented by Jin and Branke in \cite{Jin2005303}, while more novel
papers such as \cite{DBLP:journals/corr/QianYZ13,6931307} and
\cite{Qian:sampling} include brief updates. Goh and Tan \cite{goh2007investigation} performed a similar survey, focused on
multiobjective optimization.
% Alberto - the phrase below is IMHO useless
%Increasingly more papers are concerned
%with this type of optimization, so this makes more interesting any
%advance in this field. 
% right - JJ

In their survey, Jin and Branke state that uncertainty is categorized into noise, %Pablo: Paloma suggested connect this paragraph, I added "For example", sounds right?
%Alberto - nah, I think it kind of follows from above
robustness issues, fitness approximation, and time-varying fitness
functions. In addition, different options for dealing with the uncertainty are
discussed. In principle, the 
approach presented in this paper is designed to model the first kind of
uncertainty, namely, noise or uncertainty in fitness evaluation. It
can be argued that there is uncertainty in the true fitness as
stated in the third 
category. However, we think that, in general,
the third issue refers to the case in which expensive fitness
functions are replaced by surrogate functions which carry a certain
amount of error, and whose value varies as the surrogate models are
updated. Independently from the origin of uncertainty, Jin and Branke suggest
several methods to tackle it, based either on {\em implicit} / explicit 
averaging over fitness measures \cite{hansen2009method,esteban2015implicit} 
or on a threshold imposed during the selection phase. Papers such as Stroud's
\cite{stroud2001kalman}, Esteban-D{\'i}az's \cite{esteban2015implicit} or Di Mario's \cite{di2015distributed} use
this kind of approach to deal with noise. 
% [Pedro] Add here the reference to the work by Flores2011
Other authors \cite{Flores2011} propose to use 
a new rank-based selection operator and a new rank-based mutation operator 
in order to evolve a neural network topology
used as a controller for a robot. Results show that those operators are 
suitable for problems where the fitness landscape is noisy.

Since then, several other solutions for uncertainty have
been proposed. A usual approach for scientists more focused
on obtaining a straightforward solution to the optimization problem without
%not concerned not on solving the problem of noise, but on
%a straightforward solution of the optimization problem without
modifying existing tools and methodologies, is
just to disregard the noise in the fitness and take whatever  %[Pedro] I don't understand this sentence. What's is the subject for "use" in this sentence? (check the correspondence).
% take, as in using it as the real fitness.
value is returned by a single evaluation, often after re-evaluating all individuals at each
generation. This option seems to work especially well if the population is
large \cite{hansen2009method}, since the selective pressure is lower
and solutions have the chance to be evaluated several times before
being selected or discarded; this leads, if the population is large
enough, to an {\em implicit averaging} as mentioned in \cite{Jin2005303}.
This solution is exploited in our previous research in
games, although one evaluation in some of these works consists, in
  fact, of an average of several evaluations, on different maps or
  considering different opponents, see for instance 
  \cite{bots:evostar,DBLP:journals/jcst/MoraFGGF12,liberatore:pacman},  
or in the evolution of neural networks \cite{castilloGECCO99,merelo:ESNN}. 

The key to the efficiency of this approach stems from the fact that
selection used in evolutionary algorithms 
is usually stochastic, so uncertainty in fitness evaluation
could have the same effect as randomness in selection or a higher mutation
rate, which might make the evolutionary process easier 
in some particular cases
\cite{DBLP:journals/corr/QianYZ13}. 
In fact, Miller and Goldberg proved that an infinite population would not
be affected by noise \cite{miller1996genetic} and Jun-Hua and Ming studied the
effect of noise in convergence rates \cite{Junhua20136780}, proving
that an elitist genetic algorithm finds at least one solution in noisy
environments with probability one,
% Alberto - "finds at least one solution"? What does it mean?
% beats me. I'll have to check out the paper - JJ
% Checked it out. It says exactly that. - JJ
% Alberto - uh...but is the solution a global optimum, a local optimum...?
although with a lowered convergence rate. This possible positive
effect of uncertainty in evaluation leads to some authors calling it
``a blessing and the curse'' in the context of surrogate models
\cite{ong2006curse}, which, as we have seen before, carry with them a degree of
uncertainty and randomness. 

In real-world problems, however, populations are finite: in fact, using large populations
decreases the algorithm's efficiency and can be time consuming, so the usual approach for dealing with
fitness with a degree of randomness is to enlarge the population
to a value bigger than would normally be needed in a non-noisy environment, while keeping it to a manageable size.   
Furthermore, it has been recently proved that using two parents to
generate offspring, that is, crossover, 
is able to successfully deal  with noise \cite{2015arXiv150202793F}, while an
evolutionary algorithm based mainly on mutation,
such as the $\mu$+1 EA, or evolutionary programming \cite{Fogel1966}, 
would suffer a considerable degradation of performance. 
However, crossover is part of the standard kit of evolutionary
algorithms, so using it and increasing the population size has the
advantage that no special provision or change in the implementation
has to be made. %just different values of the standard parameters;
There is no big decreasing in efficiency as long as oversized
populations are not used. Using oversized populations, however, might
have a good effect on the algorithm in general, if appropriate computational resources are available \cite{DBLP:conf/lion/LaredoDFGB13}. 

%Besides using implicit averaging with oversized populations, another
Another way to deal with uncertainty which is
more theoretically sound is using {\em real} averaging, that is, 
% Alberto - the part that begins with "a statistical central tendency" is not very clear, what do we want to tell the reader?
a statistical central tendency
indicator, which usually is  the {\em average}; average happens to be
equal to the median in the case of the random variable following the
normal distribution. In this case, resampling is used to acquire a
statistically significant amount of measures and then the average is
computed over them. 
This strategy has been called
{\em explicit averaging} by Jin and Branke, and it is used, for instance,
in \cite{Junhua20136780}. Explicit averaging decreases the fitness variance,
thus reducing uncertainty, but defining the appropriate sample size for the averaging
process is not straightforward \cite{aizawa1994scheduling};
%the problem is that it is not clear in advance what would be the
%sample size used for averaging \cite{aizawa1994scheduling} and,
besides, this central tendency might not be representative % Alberto - of what?
if the
noise is not centrally distributed, as proved in \cite{merelo2016statistical}.
Our research group uses this approach in some cases, with an important difference: 
individuals are not re-evaluated every additional generation, but
their fitness value is the average of several evaluations, performed immediately \cite{DBLP:journals/jcst/MoraFGGF12}. 
Most authors use several measures of fitness for each new individual
\cite{costa2013using}, although other averaging strategies have also
been proposed, for example averaging over the neighbourhood of the
individual or using {\em resampling}, that is, heuristically requiring more fitness measurements
%more measures of fitness in a
%number which is decided heuristically
\cite{liu2014mathematically}. This assumes that there is, effectively,
a real average of the 
fitness values, which is true for Gaussian random noise and other
distributions (such as Gamma's or Cauchy's), but it does not
necessarily hold for all distributions. In this paper, we are
going to model these distributions in order to verify whether this
assumption is indeed correct. 

% Alberto - now, in this paragraph below and in the one before, we talk about resampling, but every time it gives me the impression it was supposed to be the first time (or maybe the only time)
% Can't understand you here - JJ
% Alberto - basically, we are re-explaining what resampling is, multiple times.
To the best of our knowledge, 
other central tendency measures such as the median, which might be more adequate for 
certain noise models, %but which is the same for the normal
%distribution usually attributed to noise, 
have not been tested; the median always exists,
while the average might not exist for non-centrally distributed
variables. Besides, most models keep the number of evaluations fixed 
and independent of its value, % Alberto - which value? The fitness value?
which might result in bad individuals
being evaluated multiple times before finally being discarded; some authors have
proposed {\em resampling},
\cite{RadaVilela2014,6900521},
which will effectively increase the number of
evaluations and thus slow down the search. In any case, using explicit averaging usually requires just a small change to the algorithm framework, by
using the average of several evaluations as the new fitness function.
Thus, it is usually the method preferred by researchers and practitioners using off-the-shelf
libraries such as ECJ\cite{luke2006ecj}.

In order to improve the efficiency of the algorithm, or the running
time, these two averaging approaches that are focused on the evaluation process might
be complemented with changes to the selection process. For instance,
a threshold \cite{Rudolph2001318,6900521} that is related to the noise characteristics to
avoid making comparisons of individuals that might, in fact, be very
similar or statistically the same; this is usually called {\em
  threshold selection} and can be applied either to explicit or
implicit averaging fitness functions. 
% Alberto - I don't understand the phrases below, until the end of the paragraph. "The algorithms used for solution"? Also, is it not re-sampling all over again?
Uncertainty can also be used to compare different algorithms, with some authors proposing,
instead of taking more measures,   
testing different solvers \cite{cauwet2014algorithm}, some of which
might be more affected by noise than others. However, recent papers
have proved that sampling might be ineffective \cite{Qian:sampling} in
some types of evolutionary algorithms, adding running time without an
additional benefit in terms of performance. This is one lead we will
try to follow in the current paper, by modeling noise in order to
eventually design an algorithm that behaves correctly in that environment.
% Is this better? - JJ
% Alberto - Much better!

All the aforementioned approaches still face the issue of the statistical
representation of the {\em true} fitness, even more so if there are instead
several measures that represent, {\em as a set}
the fitness of an individual, such as the case study described 
in \cite{merelo2016statistical}. This is what
we have been using in many of our papers: a method that uses resampling via an
 memory attached to every individual that stores all fitness measures % Alberto - what is "an individual memory"?
 % all fitness measurements - JJ
and uses either explicit averaging or statistical
tests like the non-parametric Wilcoxon test. 
In order to test this approach on benchmark problems
more realistic that the ones adopted so far, we need
to characterize the noise that
actually appears in games and other real-world case studies for optimization. 

% ******************************************************************************

\section{Case studies used in this paper}
\label{sec:problems}

% Antonio - reescribo el texto para cambiar el orden
The fitness of four different case studies, all related to
computational intelligence in games, are described in this paper:
generation of character backstories in artificial worlds, described in
subsection \ref{ss:made}, optimization of bots for playing the real
time strategy game (RTS) Planet Wars in \ref{ss:pw}, optimization of
the ghost team in Ms. Pac-Man, which will be described in subsection
\ref{ss:pacman}, automatic generation of autonomous players for
the famous RTS StarCraft, explained in subsection \ref{ss:starcraft}
and an artificial neural network optimization problem using an EA \ref{ss:gprop}. 
These five problems have been chosen for two main reasons: the origin of uncertainty
is different for each of the case studies; and data for the experiments is readily
available, with the possibility of
running further experimental trials, if needed.
%the the most important of 
%which is that we have been working on them and thus have data 
%available; another reason is that the origin of the uncertainty is
%different in the four cases. 
In the case of MADE, fitness is computed
through a simulation; in the case of Planet Wars, the bot
themselves have a random component, with its representation including
probabilities of different courses of action;  in Ms. Pac-Man, uncertainty lies in the 
nature of the game itself; and the huge amount of possibilities in StarCraft, 
with a considerable number of units behaving independently, creates an extremely high source of uncertainty. These scenarios are not a complete representation 
of all possible causes of uncertainty in optimization, 
but we think that the sample is big and varied enough to 
generalize the obtained results, which will be presented in the next section. 

%[Pedro] in the "Experiments and Results" the order of reporting the resulst is different to the previously proposed: (1)Ms.Pac-man (2)MADE (3)Planet Wars
% in "Experiments and Results" section the order is (1)MADE (2)Planet Wars (3)Ms.Pac-man 
% This is not so important, but I think it should be the same order...
% Antonio - opino igual, pero habría que cambiar los textos (en los experimentos, o al principio de esta sección)
% The order is for the sake of argument. It does not matter that it is
% different - JJ

%---------------------------------------------------------

\subsection{Creation of character backstories}
\label{ss:made}

MADE (MAssive Drama Engine for non-player characters)
\cite{garcia14my} is a framework for the automatic generation of
virtual worlds that allow the emergence of backstories for secondary
characters that can later on be included in videogames. In this context, an {\em archetype}
is a well-known behaviour present in the imaginary collective (for
example, a ``hero'' or a ``villain''). Given a fitness that takes into account the
existence of different $N_a$ archetypes for a virtual world, MADE uses
a genetic algorithm to optimize the parameter values of a Finite State
Machine (FSM) that models the agents of that world. For the evaluation,
a world is simulated using this parameter set, and the log is analyzed
to detect behaviours of the world agents that match the desired
archetypes. 

As the evolved parameters are the probabilities to jump from one state
to another in the FSM, each fitness evaluation is performed executing
the virtual world five times per individual, obtaining the average
fitness. Selection is, therefore, performed comparing this average
fitness, with a binary tournament. Fitness values range
from 0 to $N_a$, and are calculated taking into account the rate of occurrence of the archetypes in the execution log. 

%---------------------------------------------------------

\subsection{A `simple' real-time strategy game: Planet Wars}
\label{ss:pw}

Planet Wars \cite{DBLP:conf/cec/Fernandez-AresMGGF11} is a
simple Real-Time strategy (RTS) game. In RTS games, 
%are not turn-based and their objective 
the objective is to defeat the enemy using resources available in
the map to build and manage units and structures: differently from turn-based
strategy games, in RTS all choices have to be performed in real time.

%Computational intelligence
%methods have been applied to 
Planet Wars provides a
simplification of the elements of the RTS: one kind of unit
(spaceships) and one kind of resources and structures
(planets). Spaceships are automatically generated on the planets controlled by a player,
and they are used to conquer enemy planets, the main way to defeat the enemy.
%as this is the objective of the game. 

In this paper we are % Alberto - which paper? The current, or the Planet Wars one?
%this one - JJ
using the results obtained from the Genebot algorithm \cite{EvoStar2014:GPBot}. This
algorithm optimizes the parameters of a hand-coded FSM that indicates how many ships send from each
planet to attack or reinforce another planet depending of some other values (such as the distance between planets). The generated bot is not
deterministic, as some of the jumps of the states are based on
probabilities. 
Fitness is calculated confronting five times the bot obtained from the parameter set of the FSM against
a competitive hand-coded bot. The result of each match takes into account the `slope' of the number of player spaceships
during the time of the match. Positive results mean that the bot won,
as the slope will be positive, and vice versa. Theoretical values are
in the range $[-1,1]$, although these values are impossible to attain
in the game. A value of -1 would indicate that the player lost all
their ships in the initial time, while $1$ would mean the contrary: it
generated all the spaceships and won in the initial time. The fitness
of an individual is the sum of all five results, and therefore being
in the range $[-5,5]$. This fitness measurement is explained in more detail
in \cite{Fernandez-Ares_COSECIVI14}.  

%---------------------------------------------------------

% Alberto - for the Ms. Pac-Man case study, the structure of an individual is not explained at all, maybe it should be added?
% Don't know if its worth the while. We are only concerned with the
% fact that the fitness behaves that way - JJ
% Alberto - but it could be useful to the reader, just to know whether it's a fixed-length vector of real values, or something more complex.
% Beats me. I think it is just score. Will have to read over again the
% paper, and there's no time - JJ

\subsection{Ghost team optimization}
\label{ss:pacman}

Ms. Pac-Man is a variant of the famous Pac-Man game that extends its
mechanics with several extra features, the most interesting being
the inclusion of a random event that
reverses the direction of the ghosts. This game is used in 
the Ms. Pac-Man vs Ghosts competition \cite{Lucas2009}, where participants can submit
controllers for both Ms. Pac-Man and the Ghost Team, the first trying
to maximize its score, the second trying to minimize Ms. Pac-Man's. 
The framework used to test the methodology analyzed defines the
following restrictions for the Ghost Team: 
\begin{itemize}
 \item A ghost can never stop and if it is in a corridor it must move forward.
 \item A ghost can choose its direction only at a junction.
 \item Every time a ghost is at a junction the controller has to provide a direction from a set of feasible directions.
 \item After 4000 game ticks, a level is considered completed and the game moves on to the next one.
\end{itemize} 

In the methodology applied to this case study, published in \cite{liberatore:pacman}, the fitness of each individual is computed as the maximum
score obtained by eight different Ms. Pac-Man controllers. Some of these controllers are the champions of
past editions of the international competition, so they are very
tough rivals for the ghost team.

%---------------------------------------------------------

\subsection{A complex real-time strategy game: StarCraft}
\label{ss:starcraft}

StarCraft has become a {\em de facto} testbed for AI research in complex RTS games \cite{OntanonSURCP13}. In fact, given the high variety of game features, such as configuration options, game modes, units, maps, etc; along with the existence of several frameworks and tools related with it; researchers have exploited the game for a great variety of topics: micro and macro management of units, temporal and spatial reasoning, battle planning, combat results prediction, optimal paths and uncertainty addressing, among others. % Alberto - what is "uncertainty addressing" in this context?

The individuals described in this subsection have been generated using StarCraftGP \cite{Garcia15StarcraftGP}, a Genetic Programming (GP) [Koza1994] framework that automatically generates the source code of high-level strategies of bots. As in previous problems, the fitness of one individual is computed pitting the bot against different enemies, each one following a different strategy. 
More specifically, in this case every individual faces three {\em tiers} of enemies (considered as weak, medium and strong rivals), each tier with four different enemies. 
% Antonio - are they 'different' as I have written?
% Alberto - Yes, you have 4 different bots in each tier, for a total of 12 bots
The original fitness function assigns a higher weight to a victory against the stronger enemies, so one victory in a higher tier is considered better than four in the immediately lower one. 
% Antonio - Check my rephrasing and please try to clarify this giving a more complete explanation. Is the paragrpah below explaining this? ;) Pablo: fixed and explained below again

Conversely, to ease comparisons among noise in the present study, we have calculated an aggregated fitness function that still respects this decision, that is, prioritizing victories of harder tiers, 
% Antonio - Which decision do you refer to? Pablo: explained
giving different weights to each tier. The following equation describes the fitness function:
\begin{equation}
F_{StarCraft}=21\times A + 5\times B + C + R
\end{equation}

Where $A$ is the number of victories against enemies in the strongest tier, $B$ is the number of victories against the middle tier, and $C$ is the number of victories against the weakest enemies. Thus, for example, one victory in the middle tier is worth more points (5 points) than 4 victories in the weak tier (4 points). Also, a coefficient of the aggregated score at the end of all the games, $R$ has been added, in order to deal with ties in number of victories. This is in fact an internal score computed by the game, that takes into account all the aspects of a match, ranging from the number of kills to the type and quality of units built. 
% Antonio - Please, explain this better. ;) Pablo: Done

Moreover, the evaluation process is quite time-consuming, so, in order to save execution time, at least one enemy of the weak tiers must be defeated before allowing the individual access the higher tier. To this end, if a bot does not win against weaker rivals, we consider it cannot defeat the stronger ones: so, the evaluation terminates at that point, with the current score.
% Antonio - with the current score, right? Pablo: yes, yes.


%---------------------------------------------------------
% Alberto - here, you should probably explain better the structure of an individual and the characteristics of the fitness function...right?
% Please, Alberto, do it yourself - JJ
% Alberto - I was referring to the Artificial Neural Networks project (below), to which I did not participate, and of which I know nothing about :-)
\subsection{Artificial Neural Networks Optimization Using an EA: GProp}
\label{ss:gprop}

Designing an artificial neural network is not an easy process, as 
it requires setting a layer structure with connections among the different 
components, tuning several parameters (such as the initial weights) 
and defining a set of learning constants. Then, a training method must be used, 
which is usually an iterative gradient descent algorithm.

G-Prop (''genetic backpropagation'') \cite{CastilloNPL,castilloNC,ieeeanova2002} 
attempts to solve the problem of finding 
appropriate initial weights and learning parameters for a single hidden layer 
of a Multilayer Perceptron (MLP), by combining an EA and QuickProp method \cite{FahlmanQP}. 
The EA selects the MLP's initial weights, picks its learning rate, and changes the 
number of neurons in the hidden layer through the application of specific genetic operators.

G-Prop is a hybrid algorithm that leverages the capabilities of two classes 
of algorithms: the ability of the EA to find a solution close to the global 
optimum, and the ability of the QuickProp algorithm to tune a solution and reach 
the nearest local minimum by means of a local search performed from the 
solution found by the EA.


% ******************************************************************************

\section{Experiments and Results}
\label{sec:res}

With the case studies presented above, data on fitness values is collected by
selecting a few random individuals in every generation of the considered EAs,
and measuring
their fitness 100 times, intentionally using much more repetitions than a normal optimization method would. Thus, every individual is represented by a
random variable sampled 100 times. % Alberto - can we replace "with the 100 measures taken with its fitness" with "sampled 100 times"? Would it make sense?
% Done. Thanks - JJ
According to the usual assumptions, this random variable
should follow a normal distribution, with a certain $\sigma$
and centered on the {\em true} fitness value. In order to verify this
hypothesis, we plotted the distribution's {\em skewness}, that is, its
asymmetry, and its {\em kurtosis}, which is a parameter related to its
shape \cite{groeneveld1984measuring}
% Alberto - is there a reference for skewness and kurtosis?
% Added citation - JJ
A symmetrical distribution, like the normal
distribution, has skewness and kurtosis equal to 0; asymmetric
distributions, such as the Gamma that we had found in previous papers
\cite{merelo14:noisy}, have non-zero skewness and kurtosis,
related to their $\theta$ and $\kappa$ parameters, for instance. These
parameters are what defines the statistical distribution; $\kappa$ is
the shape parameter and skewness is $2/\sqrt{\kappa}$, which means
that it is only 0, corresponding to normality, if $\kappa$ is too
big. Kurtosis is $6/\kappa$, implying the same. 
% Alberto - yes, but what are \alpha and \kappa? They are introduced here, but not explained
A random variable can have skewness and kurtosis fixed at any value: thus, we present
these values in the following figures, with skewness
plotted as the $x$ axis against kurtosis on the $y$ axis.

\begin{figure}[htb]
  \centering
<<made,cache=FALSE,echo=FALSE,warning=FALSE>>=
s.k <- data.frame(Gen=character(), 
                  Skewness=character(),
                  Kurtosis=character(),
                  stringsAsFactors=FALSE)

for ( i in c(64,128,256)) {
    for ( j in unique(subset(made.data,Gen==i)$ID) ) {
        this.data <- subset(made.data,Gen==i & ID==j)$Fitness
        s.k <- rbind( s.k
                     , data.frame(Gen=paste("Gen",i)
                                  ,Skewness=skewness(this.data)
                                  ,Kurtosis=kurtosis(this.data)))
    }
}

ggplot(s.k,aes(x=Skewness,y=Kurtosis,color=Gen))+geom_point()+scale_x_continuous(limits=c(-1,2.5))+scale_y_continuous(limits=c(-1,8))+theme_bw()

@ 
\caption{Skewness and kurtosis for fitness in several generations of
  the MADE problem. Different colors represent different generations.}
\label{fig:made}
\end{figure}

% Antonio - yo cambiar?a los s?mbolos de cada serie de datos. Es dif?cil distinguirlas en las gr?ficas.

Figure \ref{fig:made} represents skewness and kurtosis in the MADE case study, 
for which
we took measures of a variable amount of individuals every
generation, from 100 in generation 64 to around 50 in the latest
generation. The number was variable because some of them stopped
before finishing. Anyway, the number of measurements is enough for the
statistical analysis.
% Alberto - ok, but why? Why didn't you take 50 individuals in every generation?
% It takes a good while to do so - JJ
% Alberto - I see; but this is a weak point that some reviewers might dislike...
As generations proceed, a curious convergence towards the normal
distribution is observed; in the first
generations, values of skewness and kurtosis are quite high and
correspond to an arbitrary distribution (Beta or uniform): however, as
the simulation proceeds, the two values approach zero. It must be noted, however, 
that they do not
converge exactly to 0, meaning that, even if uncertainty in this case can be
approached by a normal distribution, such an approximation would only be
correct for the latest generations of the simulation. In general, individual
fitness in MADE will follow an arbitrary distribution with a general shape and
asymmetry. 

\begin{figure}[htb]
  \centering
<<planetwars,cache=FALSE,echo=FALSE,warning=FALSE>>=
pw.s.k <- data.frame(Gen=character(), 
                  Skewness=character(),
                  Kurtosis=character(),
                  stringsAsFactors=FALSE)

for ( i in c(1,50)) {
    for ( j in unique(subset(planetwars.data,Gen==i)$ID) ) {
        this.data <- subset(planetwars.data,Gen==i & ID==j)$Fitness
        pw.s.k <- rbind( pw.s.k
                     , data.frame(Gen=paste("Gen",i)
                                  , Skewness=skewness(this.data)
                                  , Kurtosis=kurtosis(this.data)))
    }
}

ggplot(pw.s.k,aes(x=Skewness,y=Kurtosis,color=Gen))+geom_point()+scale_x_continuous(limits=c(-1,2.5))+scale_y_continuous(limits=c(-1,8))+theme_bw()
@ 
\caption{Skewness and kurtosis for fitness in several generations of
  the Planet Wars problem. Different colors represent different generations.}
\label{fig:pw}
\end{figure}

The shape of the graph for the Planet Wars case study, shown in Figure
\ref{fig:pw} for two different generations, is different but shares
some similarities. The dispersion also decreases as evolution proceeds,
with the shape of the distribution becoming closer to the normal distribution in generation
50. Nevertheless, the initial kurtosis is quite high and values above 2 and
below 0 are found even later in the evolution. Noise is, thus, {\em
  noisy} and does not conform to a single shape, even less a normal
one; this implies that using a single statistical model to represent
noise will never be too close to reality, since the shapes of the
statistical distribution are, in general, away from the normal
distribution and then different among themselves even for a single
problem, that is, the shape of the statistical distribution of fitness
values in uncertain environments is, itself, uncertain or {\em noisy}.
% Alberto - I am not sure I understood this phrase...
% Explained a bit. Thanks for the suggestions - JJ

\begin{figure}[htb]
  \centering
<<pacman,cache=FALSE,echo=FALSE,warning=FALSE>>=
pm.s.k <- data.frame(Gen=character(), 
                  Skewness=character(),
                  Kurtosis=character(),
                  stringsAsFactors=FALSE)

for ( i in c(1,25,50)) {
    for ( j in unique(subset(pacman.data,Gen==i)$ID) ) {
        this.data <- subset(pacman.data,Gen==i & ID==j)$Fitness
        pm.s.k <- rbind( pm.s.k
                        , data.frame(Gen=paste("Gen",i)
                                     , Skewness=skewness(this.data)
                                     , Kurtosis=kurtosis(this.data)))
    }
}

ggplot(pm.s.k,aes(x=Skewness,y=Kurtosis,color=Gen))+geom_point()+scale_x_continuous(limits=c(-2,10))+scale_y_continuous(limits=c(-5,100))+theme_bw()
@ 
\caption{Skewness and kurtosis for fitness in several generations of
  the Ms. Pac-Man problem. Different colors represent different generations.}
\label{fig:pm}
\end{figure}

The graph for the third case study, ghosts in Ms. Pac-Man, is different in several
aspects, and is shown in Figure \ref{fig:pm}. First we have to take
into account, as explained in \ref{ss:pacman}, that differently from
the previous cases, the fitness for a ghost team is the maximum, not
an average of several values. This causes a curious behavior of
fitness: in the first generation, several individuals have {\em crisp}
values; however, this is less and less true, becoming more ``random'' as
generations proceed, that is, the set of values the fitness has got
begins to have many different values while in the first generations it
had one or a few. To put it in another words, in the first generation
the set of fitness measures could look like \texttt{\{x x x y x x x\}}. As
evolution proceeds, the measures in the set tend to be all different
% Alberto - I could not understand the last phrase ^_^;
% Hope it works now - JJ 
% Alberto - Yes, it works!
That is why the behavior shown in the graph is
completely different: distributions get increasingly asymmetric and
their shape grows further away from a normal distribution and closer to a
Beta distribution. Even if the trend is different from the other two
problems, the overall aspect is the same: there is no single
distribution that is able to describe the shape of fitness with an
uncertainty component, for all considered generations.

\begin{figure}[htb]
  \centering
<<starcraft,cache=FALSE,echo=FALSE,warning=FALSE>>=
sc.s.k <- data.frame(Gen=character(), 
                     Skewness=character(),
                     Kurtosis=character(),
                     stringsAsFactors=FALSE)

for ( i in c(1,15,30)) {
    for ( j in unique(subset(starcraft.data,Gen==i)$ID) ) {
        this.data <- subset(starcraft.data,Gen==i & ID==j)$Fitness
        sc.s.k <- rbind( sc.s.k
                      , data.frame(Gen=paste("Gen",i)
                                 , Skewness=skewness(this.data)
                                 , Kurtosis=kurtosis(this.data)))
    }
}

ggplot(sc.s.k,aes(x=Skewness,y=Kurtosis,color=Gen))+geom_point()+scale_x_continuous()+scale_y_continuous()+theme_bw()
@ 
\caption{Skewness and kurtosis for fitness in several generations of
  the Starcraft problem. Different colors (or shades of gray) represent different generations.}
\label{fig:sc}
\end{figure}
%
%
\begin{figure}[htb]
  \centering
<<mlp,cache=FALSE,echo=FALSE,warning=FALSE>>=
mlp.s.k <- data.frame(Gen=character(), 
                      Skewness=character(),
                      Kurtosis=character(),
                      stringsAsFactors=FALSE)

for ( i in c(0,49,99)) {
    for ( j in unique(subset(mlp.data,Gen==i)$ID) ) {
        this.data <- subset(mlp.data,Gen==i & ID==j)$Fitness
        mlp.s.k <- rbind( mlp.s.k
                      , data.frame(Gen=paste("Gen",i)
                                 , Skewness=skewness(this.data)
                                 , Kurtosis=kurtosis(this.data)))
    }
}

ggplot(mlp.s.k,aes(x=Skewness,y=Kurtosis,color=Gen))+geom_point()+scale_x_continuous()+scale_y_continuous()+theme_bw()
@ 
\caption{Skewness and kurtosis for fitness in several generations of
  the MLP training problem. Different colors (or shades of gray)
  represent different generations.} 
\label{fig:mlp}
\end{figure}

The last game we have evaluated is StarCraft, with kurtosis and
skewness shown in Figure \ref{fig:sc}. In this case evaluation takes a
very long time, that is why only a few samples were available. That
might be the reason it is not quite clear if there is a trend. The
latest generation seems to be a bit closer to normal distribution, but
intermediate generations tend to have a high value. However, even if
values seem to be closer in generation 30, they are in some cases
positive and in other negative, indicating a distribution that is
flatter than the Gaussian and with the {\em bump} more loaded to the
right of the center. Once again, this proves that using non-parametric
methods like Wilcoxon are a better approach than using central
measures such as the average.

For the sake of completeness, we have also included in this paper a
problem that comes from a different area: genetic optimization of
neural networks. The skewness/kurtosis graph is included in Figure
\ref{fig:mlp}. Since the problem is completely different, the
distribution of the values is also completely different. For starters,
skewness tends to be negative, indicating distributions with a long
tail to the right; that means that, even if the value is centered
along a particular value, there are many values that are larger that
this central value. Once again, resampling cannot change the fact that
the average will not be an accurate description for the whole
data. Besides, values tend to get closer to 0, 0, but in every
generation there is values quite far away from them; in the last
generation, a neural net whose fitness distribution has kurtosis of
15, indicating a very sharp bump, is present, but it also has a low
kurtosis of almost -4, indicating a long tail to the right. The
conclusion in this case is similar: values tend to change, but they
keep away from a single kurtosis and skewness, even less so if both of
them are 0. 

% ******************************************************************************%

\section{\uppercase{Conclusions}}
\label{sec:conclusion}

\noindent In this paper we set out to study the statistical
distribution that best fits  the stochastic fitness values of single individuals 
in several case studies in the area of games; we have also included a
genetically optimized neural network for the sake of comparison.
Stochastic optimization algorithms applied to
MADE, Planet Wars, Ms. Pac-Man, and StarCraft exploit different ways to
compute the fitness values, but for all of them the fitness value is
not a fixed number but a random variable; this is also the case in
G-Prop, the genetically optimized multilayer perceptron. We
prove the hypothesis that not only noise does not follow the normal,
or Gaussian, distribution, or other centrally-distributed models such
as Cauchy, which have been used repeatedly in the literature; but also
it does not follow a single, particular distribution even when considering a single
case study or a single generation.

%The study presented here proves that hypothesis. 
This conclusion follows from our study of the parameters of the
statistical variables that describe fitness. The best way to describe them is using two
parameters: kurtosis and skewness. These two parameters have been
computed and plotted for candidate solutions extracted from each one of the case studies, 
proving that not
only distributions are asymmetrical and not bell-shaped, but that their
shape changes within a single problem and in different stages of the
computation. In some case, like MADE, it seems clear that due to the
fact that averages are used as a representative for selection, 
individuals whose fitness is closer to a central shape are oversampled
and thus selected preferably, with almost-central individuals in the
latest stages being a consequence of this fact. In other cases, when
fitness is computed in a different way or selection takes another
form, the effect is exactly the opposite. At any rate, using averages
or other central measures like the median is discouraged 
after the study done in this paper since in many cases
and almost always in the early stages of the evolution, fitness, being
a random variable, does not pass a centrality test and it might not
even possess a reliable, that is, statistically significant,
average. A better way of comparing any fitness with 
uncertainty would be, as proposed by the authors, using non-parametric
tests such as the Wilcoxon test that impose a partial order on the
individuals \cite{merelo14:noisy}; this partial order can be used, in
several different ways, for selection. 

The fact that there is no single model representing the distribution
of fitness also implies that it is an error to use centrally
distributed random variables added to a  crisp fitness to test
operators and algorithms that operate in uncertainty. Either real
values should be used, such as the ones proposed above, or a
distribution with varying shape and symmetry such as Beta. However, in
this case we should take into account that ``true'' 
or ``crisp'' fitness {\em does not really exist}, so any modelization
of uncertain values that uses noise added to a crisp fitness is, in the
more general case, wrong, although it might still return correct results in some cases. 
% Alberto - I could not understand the paragraph below
If the fitness evaluation is expensive and tests have to be
performed for new selection operators, the best way to model uncertainty
would be to use {\em different} statistical models applied to every individual,
with different skewness and kurtosis. However, this would be only a
first-order approximation and it might still favor methods that use
averages.
%Hope it works now - JJ
% Alberto - Yes, now I get it.

What remains to be done is to effectively apply Wilcoxon-based
comparisons to the case studies above. Since real-world case studies are computationally expensive to
evaluate, we plan to create a benchmark for problems with
uncertainty which reflects in the best possible way how fitness is
organized in a wide array of problems. In order attain this goal, we will 
examine as many uncertain problems as possible, in the attempt to deduce a model of noise what as general as possible. 


\section{\uppercase{Acknowledgements}}

This work has been supported in part by projects TIN2014-56494-C4-3-P (Spanish Ministry of Economy and Competitiveness), 
SPIP2014-01437 (Direcci{\'o}n General de Tr{\'a}fico), 
PRY142/14 (Fundaci{\'o}n P{\'u}blica Andaluza Centro de Estudios Andaluces en la IX Convocatoria de Proyectos de
Investigaci{\'o}n), 
PROY-PP2015-06 (Plan Propio 2015 UGR), 
and project CEI2015-MP-V17 of the Microprojects program 2015 from CEI BioTIC Granada. 

\bibliographystyle{splncs03}
\bibliography{geneura,GA-general,noisy}

\end{document}
%%% Local Variables:
%%% ispell-local-dictionary: "english"
%%% hunspell-local-dictionary: "english"
%%% End:

